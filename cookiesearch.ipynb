{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data container not found on page 1. Skipping...\n",
      "Data container not found on page 2. Skipping...\n",
      "Data container not found on page 3. Skipping...\n",
      "Data container not found on page 4. Skipping...\n",
      "Data container not found on page 5. Skipping...\n",
      "Data container not found on page 6. Skipping...\n",
      "Data container not found on page 7. Skipping...\n",
      "Data container not found on page 8. Skipping...\n",
      "Data container not found on page 9. Skipping...\n",
      "Data container not found on page 10. Skipping...\n",
      "Data container not found on page 11. Skipping...\n",
      "Data container not found on page 12. Skipping...\n",
      "Data container not found on page 13. Skipping...\n",
      "Data container not found on page 14. Skipping...\n",
      "Data container not found on page 15. Skipping...\n",
      "Data container not found on page 16. Skipping...\n",
      "Data container not found on page 17. Skipping...\n",
      "Data container not found on page 18. Skipping...\n",
      "Data container not found on page 19. Skipping...\n",
      "Data container not found on page 20. Skipping...\n",
      "Data container not found on page 21. Skipping...\n",
      "Data container not found on page 22. Skipping...\n",
      "Data container not found on page 23. Skipping...\n",
      "Data container not found on page 24. Skipping...\n",
      "Data container not found on page 25. Skipping...\n",
      "Data container not found on page 26. Skipping...\n",
      "Data container not found on page 27. Skipping...\n",
      "Data container not found on page 28. Skipping...\n",
      "Data container not found on page 29. Skipping...\n",
      "Data container not found on page 30. Skipping...\n",
      "Data container not found on page 31. Skipping...\n",
      "Data container not found on page 32. Skipping...\n",
      "Data container not found on page 33. Skipping...\n",
      "Data container not found on page 34. Skipping...\n",
      "Data container not found on page 35. Skipping...\n",
      "Data container not found on page 36. Skipping...\n",
      "Data container not found on page 37. Skipping...\n",
      "Data container not found on page 38. Skipping...\n",
      "Data container not found on page 39. Skipping...\n",
      "Data container not found on page 40. Skipping...\n",
      "Data container not found on page 41. Skipping...\n",
      "Data container not found on page 42. Skipping...\n",
      "Empty DataFrame\n",
      "Columns: [Name, Position, Location]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"https://www.signalhire.com/companies/crumbl-cookies/employees?page={}\"\n",
    "total_pages = 42\n",
    "data = []\n",
    "\n",
    "for page in range(1, total_pages + 1):\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    data_container = soup.find(\"div\", class_=\"c-emp-cards__wrapper\")\n",
    "    if data_container is None:\n",
    "        print(f\"Data container not found on page {page}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    rows = data_container.find_all(\"div\", class_=\"c-emp-card__detail\")\n",
    "\n",
    "    for row in rows:\n",
    "        name = row.find(\"h4\").text.strip()\n",
    "        position = row.find(\"h6\").text.strip()\n",
    "        location = row.find(\"p\").text.strip()\n",
    "        data.append([name, position, location])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Name\", \"Position\", \"Location\"])\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 saved to output.txt\n",
      "Page 2 saved to output.txt\n",
      "Page 3 saved to output.txt\n",
      "Page 4 saved to output.txt\n",
      "Page 5 saved to output.txt\n",
      "Page 6 saved to output.txt\n",
      "Page 7 saved to output.txt\n",
      "Page 8 saved to output.txt\n",
      "Page 9 saved to output.txt\n",
      "Page 10 saved to output.txt\n",
      "Page 11 saved to output.txt\n",
      "Page 12 saved to output.txt\n",
      "Page 13 saved to output.txt\n",
      "Page 14 saved to output.txt\n",
      "Page 15 saved to output.txt\n",
      "Page 16 saved to output.txt\n",
      "Page 17 saved to output.txt\n",
      "Page 18 saved to output.txt\n",
      "Page 19 saved to output.txt\n",
      "Page 20 saved to output.txt\n",
      "Page 21 saved to output.txt\n",
      "Page 22 saved to output.txt\n",
      "Page 23 saved to output.txt\n",
      "Page 24 saved to output.txt\n",
      "Page 25 saved to output.txt\n",
      "Page 26 saved to output.txt\n",
      "Page 27 saved to output.txt\n",
      "Page 28 saved to output.txt\n",
      "Page 29 saved to output.txt\n",
      "Page 30 saved to output.txt\n",
      "Page 31 saved to output.txt\n",
      "Page 32 saved to output.txt\n",
      "Page 33 saved to output.txt\n",
      "Page 34 saved to output.txt\n",
      "Page 35 saved to output.txt\n",
      "Page 36 saved to output.txt\n",
      "Page 37 saved to output.txt\n",
      "Page 38 saved to output.txt\n",
      "Page 39 saved to output.txt\n",
      "Page 40 saved to output.txt\n",
      "Page 41 saved to output.txt\n",
      "Page 42 saved to output.txt\n",
      "All pages saved to output.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://www.signalhire.com/companies/crumbl-cookies/employees?page={}\"\n",
    "total_pages = 42\n",
    "output_file = \"output.txt\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for page in range(1, total_pages + 1):\n",
    "        url = base_url.format(page)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        text = soup.get_text()\n",
    "        f.write(text)\n",
    "\n",
    "        print(f\"Page {page} saved to {output_file}\")\n",
    "\n",
    "print(\"All pages saved to output.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andres not found\n"
     ]
    }
   ],
   "source": [
    "# find if output.txt contains the word \"Andres\"\n",
    "with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "if \"Andres\" in text:\n",
    "    print(\"Andres found\")\n",
    "else:\n",
    "    print(\"Andres not found\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
